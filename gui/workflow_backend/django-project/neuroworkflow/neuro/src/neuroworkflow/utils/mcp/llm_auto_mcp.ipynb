{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b08266c-dc21-49ea-a5ca-3d607ed0f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile server.py\n",
    "# server.py\n",
    "import sys, logging\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# set up logging to stderr and to a file\n",
    "logger = logging.getLogger(\"mcp-server\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fmt = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "stderr_h = logging.StreamHandler(sys.stderr)\n",
    "stderr_h.setFormatter(fmt)\n",
    "file_h = logging.FileHandler(\"server.log\", encoding=\"utf-8\")\n",
    "file_h.setFormatter(fmt)\n",
    "\n",
    "logger.handlers.clear()\n",
    "logger.addHandler(stderr_h)\n",
    "logger.addHandler(file_h)\n",
    "\n",
    "mcp = FastMCP(\"demo\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two integers and return the sum.\n",
    "\n",
    "    When to use:\n",
    "      - Any arithmetic addition request, including multi-step math where a sum is needed.\n",
    "\n",
    "    Constraints:\n",
    "      - Only integers. For floats, round first or ask the user to confirm.\n",
    "\n",
    "    Examples:\n",
    "      add(a=2, b=40) -> 42\n",
    "      add(a=321, b=123) -> 444\n",
    "    \"\"\"\n",
    "    logger.debug(f\"add() called with a={a}, b={b}\")\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the same text that was passed in.\n",
    "\n",
    "    When to use:\n",
    "      - The user asks to reflect, quote, or transform exactly without changes.\n",
    "\n",
    "    Examples:\n",
    "      echo(text=\"MCP works\") -> \"MCP works\"\n",
    "    \"\"\"\n",
    "    logger.debug(f\"echo() called with text={text!r}\")\n",
    "    return text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug(\"MCP server starting...\")\n",
    "    mcp.run(\"stdio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc7eaeb-daf5-44e3-aae2-71c8292344a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mcp openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2adf9f-34d8-4f52-ab04-4b60dfaf0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e3861a-e782-4a31-a162-83f81956475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, asyncio, sys\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "def json_read(filename: str):\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data, True\n",
    "    return {}, False\n",
    "\n",
    "async def tail_file(path: str):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(0, 2)  # jump to end\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    await asyncio.sleep(0.2)\n",
    "                    continue\n",
    "                print(\"[SERVER]\", line.rstrip())\n",
    "    except FileNotFoundError:\n",
    "        # file may not exist yet on first run\n",
    "        for _ in range(25):\n",
    "            await asyncio.sleep(0.2)\n",
    "            try:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    break\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        # try again recursively if it appeared\n",
    "        return await tail_file(path)\n",
    "\n",
    "async def build_system_prompt(session) -> str:\n",
    "    tools = (await session.list_tools()).tools\n",
    "    lines = [\n",
    "        \"You can call tools when useful. Prefer precise tool usage. If no tool is needed, answer directly.\",\n",
    "        \"\",\n",
    "        \"Available tools:\"\n",
    "    ]\n",
    "    for t in tools:\n",
    "        desc = (t.description or \"\").strip()\n",
    "        # grab the first paragraph only for brevity\n",
    "        first_para = desc.split(\"\\n\\n\", 1)[0]\n",
    "        lines.append(f\"- {t.name}: {first_para}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Use tool parameters exactly as defined in the provided tool schemas.\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "api_data, ok = json_read(\"key.json\")\n",
    "if not ok:\n",
    "    raise FileNotFoundError(\"key.json not found. Please create it.\")\n",
    "\n",
    "PROVIDER_BASE = api_data.get(\"PROVIDER_BASE\", \"\").strip()\n",
    "API_KEY       = api_data.get(\"OPENAI_API_KEY\", \"\").strip()\n",
    "MODEL         = api_data.get(\"LLM_MODEL\", \"gpt-4o-mini\").strip()\n",
    "SERVER_PATH   = api_data.get(\"MCP_SERVER\", \"server.py\").strip()\n",
    "\n",
    "#SYSTEM_PROMPT = (\n",
    "#    \"You can call tools when useful. Use add for arithmetic, echo for reflecting text. \"\n",
    "#    \"If no tool is needed, answer directly.\"\n",
    "#)\n",
    "\n",
    "def make_client() -> OpenAI:\n",
    "    # Always pass the API key from JSON to avoid relying on environment variables\n",
    "    if PROVIDER_BASE:\n",
    "        return OpenAI(base_url=PROVIDER_BASE, api_key=API_KEY)\n",
    "    return OpenAI(api_key=API_KEY)\n",
    "\n",
    "def schema_from_mcp_tool(t) -> Dict[str, Any]:\n",
    "    # Convert an MCP ToolDescriptor to OpenAI tool schema\n",
    "    params = getattr(t, \"inputSchema\", None) or getattr(t, \"input_schema\", None)\n",
    "    if not params:\n",
    "        params = {\"type\": \"object\", \"properties\": {}, \"additionalProperties\": False}\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": t.name,\n",
    "            \"description\": getattr(t, \"description\", \"\") or \"\",\n",
    "            \"parameters\": params,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def extract_text_content(mcp_result) -> str:\n",
    "    parts = []\n",
    "    for c in getattr(mcp_result, \"content\", []) or []:\n",
    "        text = getattr(c, \"text\", None)\n",
    "        if text is not None:\n",
    "            parts.append(text)\n",
    "    return \"\\n\".join(parts) if parts else \"\"\n",
    "\n",
    "async def build_openai_tools(session: ClientSession) -> List[Dict[str, Any]]:\n",
    "    tools_resp = await session.list_tools()\n",
    "    return [schema_from_mcp_tool(t) for t in tools_resp.tools]\n",
    "\n",
    "async def run_chat_once(user_msg: str) -> str:\n",
    "    client = make_client()\n",
    "\n",
    "    # Spawn the MCP server over stdio and open a session\n",
    "    params = StdioServerParameters(command=sys.executable, args=[SERVER_PATH])\n",
    "\n",
    "    # start tail task before connecting\n",
    "    log_task = asyncio.create_task(tail_file(\"server.log\"))\n",
    "    \n",
    "    async with stdio_client(params) as (read_stream, write_stream):\n",
    "        async with ClientSession(read_stream, write_stream) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            openai_tools = await build_openai_tools(session)\n",
    "\n",
    "            print(openai_tools)\n",
    "\n",
    "            #system_prompt\n",
    "            system_prompt = await build_system_prompt(session)\n",
    "            print(system_prompt)\n",
    "\n",
    "            messages: List[Dict[str, Any]] = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "            ]\n",
    "\n",
    "            for _ in range(5):\n",
    "                chat = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=messages,\n",
    "                    tools=openai_tools,\n",
    "                    tool_choice=\"auto\",\n",
    "                )\n",
    "                choice = chat.choices[0]\n",
    "                finish = choice.finish_reason\n",
    "\n",
    "                if finish == \"tool_calls\" and choice.message.tool_calls:\n",
    "                    tool_messages = []\n",
    "                    for call in choice.message.tool_calls:\n",
    "                        name = call.function.name\n",
    "                        args = json.loads(call.function.arguments or \"{}\")\n",
    "                        result = await session.call_tool(name, args)\n",
    "                        tool_messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": call.id,\n",
    "                            \"name\": name,\n",
    "                            \"content\": extract_text_content(result),\n",
    "                        })\n",
    "                    messages = messages + [choice.message] + tool_messages\n",
    "                    continue\n",
    "\n",
    "                return choice.message.content or \"\"\n",
    "\n",
    "    # stop the tailer\n",
    "    log_task.cancel()\n",
    "    try:\n",
    "        await log_task\n",
    "    except asyncio.CancelledError:\n",
    "        pass\n",
    "        \n",
    "    return \"\"\n",
    "\n",
    "# Notebook-friendly entry point\n",
    "def run_demo(prompt: str = \"Please add 123 and 456 using the tool.\"):\n",
    "    # Jupyter often has an existing event loop. Use nest_asyncio to allow nested runs.\n",
    "    import nest_asyncio, asyncio\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(run_chat_once(prompt))\n",
    "    except RuntimeError:\n",
    "        # Fallback: create a new loop\n",
    "        return asyncio.run(run_chat_once(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613e41a0-966d-4f21-89a4-a9a8d206bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'add', 'description': '\\n    Add two integers and return the sum.\\n\\n    When to use:\\n      - Any arithmetic addition request, including multi-step math where a sum is needed.\\n\\n    Constraints:\\n      - Only integers. For floats, round first or ask the user to confirm.\\n\\n    Examples:\\n      add(a=2, b=40) -> 42\\n      add(a=321, b=123) -> 444\\n    ', 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'echo', 'description': '\\n    Return the same text that was passed in.\\n\\n    When to use:\\n      - The user asks to reflect, quote, or transform exactly without changes.\\n\\n    Examples:\\n      echo(text=\"MCP works\") -> \"MCP works\"\\n    ', 'parameters': {'properties': {'text': {'title': 'Text', 'type': 'string'}}, 'required': ['text'], 'title': 'echoArguments', 'type': 'object'}}}]\n",
      "You can call tools when useful. Prefer precise tool usage. If no tool is needed, answer directly.\n",
      "\n",
      "Available tools:\n",
      "- add: Add two integers and return the sum.\n",
      "- echo: Return the same text that was passed in.\n",
      "\n",
      "Use tool parameters exactly as defined in the provided tool schemas.\n",
      "[SERVER] 2025-09-29 16:07:18,031 [DEBUG] MCP server starting...\n",
      "[SERVER] 2025-09-29 16:07:21,109 [DEBUG] add() called with a=321, b=123\n",
      "[SERVER] 2025-09-29 16:07:21,116 [DEBUG] echo() called with text='MCP works'\n",
      "The sum of 321 and 123 is 444. \n",
      "\n",
      "Also, 'MCP works'.\n",
      "[SERVER] 2025-09-29 16:07:23,208 [DEBUG] MCP server starting...\n",
      "[SERVER] 2025-09-29 16:07:24,459 [DEBUG] echo() called with text='MCP works'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_LOG\"] = \"\" \n",
    "\n",
    "print(run_demo(\"Add 321 and 123 using the tool, and then echo 'MCP works'.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3845b97-15bb-4407-b511-c54e59d19abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'add', 'description': '\\n    Add two integers and return the sum.\\n\\n    When to use:\\n      - Any arithmetic addition request, including multi-step math where a sum is needed.\\n\\n    Constraints:\\n      - Only integers. For floats, round first or ask the user to confirm.\\n\\n    Examples:\\n      add(a=2, b=40) -> 42\\n      add(a=321, b=123) -> 444\\n    ', 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'echo', 'description': '\\n    Return the same text that was passed in.\\n\\n    When to use:\\n      - The user asks to reflect, quote, or transform exactly without changes.\\n\\n    Examples:\\n      echo(text=\"MCP works\") -> \"MCP works\"\\n    ', 'parameters': {'properties': {'text': {'title': 'Text', 'type': 'string'}}, 'required': ['text'], 'title': 'echoArguments', 'type': 'object'}}}]\n",
      "You can call tools when useful. Prefer precise tool usage. If no tool is needed, answer directly.\n",
      "\n",
      "Available tools:\n",
      "- add: Add two integers and return the sum.\n",
      "- echo: Return the same text that was passed in.\n",
      "\n",
      "Use tool parameters exactly as defined in the provided tool schemas.\n",
      "[SERVER] 2025-09-29 16:07:23,208 [DEBUG] MCP server starting...\n",
      "[SERVER] 2025-09-29 16:07:24,459 [DEBUG] echo() called with text='MCP works'\n",
      "The result of 321 divided by 123 is approximately 2.607. Since division cannot be performed with the available tools, I provided the closest approximation.\n",
      "\n",
      "Additionally, here is the echoed text: \"MCP works\".\n"
     ]
    }
   ],
   "source": [
    "print(run_demo(\"devide 321 by 123 using the tool, and then echo 'MCP works'.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9afab-f514-40f5-a6c4-0311ba4a537b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
