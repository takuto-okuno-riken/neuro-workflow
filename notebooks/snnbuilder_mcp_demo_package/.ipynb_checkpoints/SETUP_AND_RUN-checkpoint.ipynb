{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-header",
   "metadata": {},
   "source": [
    "# üß†ü§ñ SNNbuilder MCP Demo: AI-Augmented Computational Neuroscience\n",
    "\n",
    "This notebook demonstrates how to use SNNbuilder nodes through MCP (Model Context Protocol) servers with LLM agents for AI-augmented computational neuroscience.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "- **Natural Language Interface**: Create neurons using plain English\n",
    "- **AI-Augmented Workflows**: LLM agents understand and manipulate neuroscience components\n",
    "- **Educational Value**: Learn neuroscience concepts through AI explanations\n",
    "- **Code Generation**: Automatic creation of standalone, reproducible Python code\n",
    "- **Domain Knowledge Integration**: Built-in neuroscience expertise guides parameter selection\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- OpenAI API key\n",
    "- Optional: NEST Simulator (for full functionality)\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, let's install all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Optional: Install NEST Simulator for full functionality\n",
    "# Uncomment the line below if you want full NEST integration\n",
    "# !pip install nest-simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "## Step 2: Configure API Key\n",
    "\n",
    "Set up your OpenAI API key for LLM interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-api-key",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check if key.json exists\n",
    "if not os.path.exists('key.json'):\n",
    "    # Create key.json from template\n",
    "    with open('key_template.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Prompt user for API key\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    config['OPENAI_API_KEY'] = \"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\"\n",
    "    \n",
    "    # Save configuration\n",
    "    with open('key.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"‚úÖ API key configured successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ key.json already exists\")\n",
    "\n",
    "# Verify configuration\n",
    "with open('key.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "if config['OPENAI_API_KEY'] == 'your-openai-api-key-here':\n",
    "    print(\"‚ö†Ô∏è  Please update your API key in key.json\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using model: {config['LLM_MODEL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "## Step 3: Setup MCP Client\n",
    "\n",
    "Now let's set up the MCP client to communicate with our SNNbuilder server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-mcp-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, asyncio, sys\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "def json_read(filename: str):\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data, True\n",
    "    return {}, False\n",
    "\n",
    "async def tail_file(path: str):\n",
    "    \"\"\"Monitor server log file for debugging.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(0, 2)  # jump to end\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    await asyncio.sleep(0.2)\n",
    "                    continue\n",
    "                print(\"[SNNBUILDER-SERVER]\", line.rstrip())\n",
    "    except FileNotFoundError:\n",
    "        # file may not exist yet on first run\n",
    "        for _ in range(25):\n",
    "            await asyncio.sleep(0.2)\n",
    "            try:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    break\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        # try again recursively if it appeared\n",
    "        return await tail_file(path)\n",
    "\n",
    "async def build_system_prompt(session) -> str:\n",
    "    \"\"\"Build system prompt with available tools.\"\"\"\n",
    "    tools = (await session.list_tools()).tools\n",
    "    lines = [\n",
    "        \"You are an AI assistant specialized in computational neuroscience using SNNbuilder.\",\n",
    "        \"You can help users create, configure, and execute neural models with biological parameters.\",\n",
    "        \"Use tools when appropriate to help users with neuron modeling tasks.\",\n",
    "        \"Always provide clear explanations of neuroscience concepts and parameter meanings.\",\n",
    "        \"\",\n",
    "        \"Available SNNbuilder tools:\"\n",
    "    ]\n",
    "    for t in tools:\n",
    "        desc = (t.description or \"\").strip()\n",
    "        # grab the first paragraph only for brevity\n",
    "        first_para = desc.split(\"\\n\\n\", 1)[0]\n",
    "        lines.append(f\"- {t.name}: {first_para}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Use tool parameters exactly as defined in the provided tool schemas.\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Load API configuration\n",
    "api_data, ok = json_read(\"key.json\")\n",
    "if not ok:\n",
    "    raise FileNotFoundError(\"key.json not found. Please run the previous cell first.\")\n",
    "\n",
    "PROVIDER_BASE = api_data.get(\"PROVIDER_BASE\", \"\").strip()\n",
    "API_KEY       = api_data.get(\"OPENAI_API_KEY\", \"\").strip()\n",
    "MODEL         = api_data.get(\"LLM_MODEL\", \"gpt-4o-mini\").strip()\n",
    "SERVER_PATH   = api_data.get(\"MCP_SERVER\", \"snnbuilder_server.py\").strip()\n",
    "\n",
    "def make_client() -> OpenAI:\n",
    "    if PROVIDER_BASE:\n",
    "        return OpenAI(base_url=PROVIDER_BASE, api_key=API_KEY)\n",
    "    return OpenAI(api_key=API_KEY)\n",
    "\n",
    "def schema_from_mcp_tool(t) -> Dict[str, Any]:\n",
    "    \"\"\"Convert an MCP ToolDescriptor to OpenAI tool schema.\"\"\"\n",
    "    params = getattr(t, \"inputSchema\", None) or getattr(t, \"input_schema\", None)\n",
    "    if not params:\n",
    "        params = {\"type\": \"object\", \"properties\": {}, \"additionalProperties\": False}\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": t.name,\n",
    "            \"description\": getattr(t, \"description\", \"\") or \"\",\n",
    "            \"parameters\": params,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def extract_text_content(mcp_result) -> str:\n",
    "    \"\"\"Extract text content from MCP result.\"\"\"\n",
    "    parts = []\n",
    "    for c in getattr(mcp_result, \"content\", []) or []:\n",
    "        text = getattr(c, \"text\", None)\n",
    "        if text is not None:\n",
    "            parts.append(text)\n",
    "    return \"\\n\".join(parts) if parts else \"\"\n",
    "\n",
    "async def build_openai_tools(session: ClientSession) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Build OpenAI tools from MCP session.\"\"\"\n",
    "    tools_resp = await session.list_tools()\n",
    "    return [schema_from_mcp_tool(t) for t in tools_resp.tools]\n",
    "\n",
    "print(\"‚úÖ MCP client setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "## Step 4: Create the Main Chat Function\n",
    "\n",
    "This function handles the communication between the LLM and the SNNbuilder MCP server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-chat-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_snnbuilder_chat(user_msg: str, show_details: bool = True) -> str:\n",
    "    \"\"\"Run a chat session with SNNbuilder MCP server.\"\"\"\n",
    "    client = make_client()\n",
    "\n",
    "    # Spawn the SNNbuilder MCP server over stdio and open a session\n",
    "    params = StdioServerParameters(command=sys.executable, args=[SERVER_PATH])\n",
    "\n",
    "    # start tail task before connecting (for debugging)\n",
    "    log_task = asyncio.create_task(tail_file(\"snnbuilder_server.log\")) if show_details else None\n",
    "    \n",
    "    async with stdio_client(params) as (read_stream, write_stream):\n",
    "        async with ClientSession(read_stream, write_stream) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            openai_tools = await build_openai_tools(session)\n",
    "\n",
    "            if show_details:\n",
    "                print(\"üîß Available SNNbuilder tools:\")\n",
    "                for tool in openai_tools:\n",
    "                    print(f\"   ‚Ä¢ {tool['function']['name']}\")\n",
    "                print()\n",
    "\n",
    "            # Build system prompt\n",
    "            system_prompt = await build_system_prompt(session)\n",
    "            \n",
    "            if show_details:\n",
    "                print(\"üß† System prompt configured\")\n",
    "                print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "            messages: List[Dict[str, Any]] = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "            ]\n",
    "\n",
    "            for iteration in range(5):\n",
    "                if show_details:\n",
    "                    print(f\"ü§ñ LLM Iteration {iteration + 1}:\")\n",
    "                \n",
    "                chat = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=messages,\n",
    "                    tools=openai_tools,\n",
    "                    tool_choice=\"auto\",\n",
    "                )\n",
    "                choice = chat.choices[0]\n",
    "                finish = choice.finish_reason\n",
    "\n",
    "                if finish == \"tool_calls\" and choice.message.tool_calls:\n",
    "                    if show_details:\n",
    "                        print(f\"   üîß Calling {len(choice.message.tool_calls)} tool(s):\")\n",
    "                    \n",
    "                    tool_messages = []\n",
    "                    for call in choice.message.tool_calls:\n",
    "                        name = call.function.name\n",
    "                        args = json.loads(call.function.arguments or \"{}\")\n",
    "                        if show_details:\n",
    "                            print(f\"      ‚Ä¢ {name}({', '.join(f'{k}={v}' for k, v in list(args.items())[:3])}{'...' if len(args) > 3 else ''})\")\n",
    "                        \n",
    "                        result = await session.call_tool(name, args)\n",
    "                        tool_result = extract_text_content(result)\n",
    "                        \n",
    "                        tool_messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": call.id,\n",
    "                            \"name\": name,\n",
    "                            \"content\": tool_result,\n",
    "                        })\n",
    "                    \n",
    "                    messages = messages + [choice.message] + tool_messages\n",
    "                    continue\n",
    "\n",
    "                if show_details:\n",
    "                    print(\"\\nüí¨ Final LLM Response:\")\n",
    "                    print(\"=\"*60)\n",
    "                return choice.message.content or \"\"\n",
    "\n",
    "    # stop the tailer\n",
    "    if log_task:\n",
    "        log_task.cancel()\n",
    "        try:\n",
    "            await log_task\n",
    "        except asyncio.CancelledError:\n",
    "            pass\n",
    "        \n",
    "    return \"\"\n",
    "\n",
    "# Notebook-friendly entry point\n",
    "def run_snnbuilder_demo(prompt: str, show_details: bool = True):\n",
    "    \"\"\"Run SNNbuilder demo with LLM interaction.\"\"\"\n",
    "    # Jupyter often has an existing event loop. Use nest_asyncio to allow nested runs.\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(run_snnbuilder_chat(prompt, show_details))\n",
    "    except RuntimeError:\n",
    "        # Fallback: create a new loop\n",
    "        return asyncio.run(run_snnbuilder_chat(prompt, show_details))\n",
    "\n",
    "print(\"‚úÖ Chat function ready!\")\n",
    "print(\"\\nüéØ You can now use: run_snnbuilder_demo('your question here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-section",
   "metadata": {},
   "source": [
    "# üöÄ Interactive Demos\n",
    "\n",
    "Now let's explore AI-augmented computational neuroscience! Each demo showcases different aspects of the SNNbuilder MCP integration.\n",
    "\n",
    "## Demo 1: Learning About Neuron Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo1-learn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to explain neuron creation\n",
    "response = run_snnbuilder_demo(\n",
    "    \"How do I create a neuron? What are the parameters and their meanings? \"\n",
    "    \"Please explain it in a way that's educational for someone learning computational neuroscience.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo2-header",
   "metadata": {},
   "source": [
    "## Demo 2: Creating a Pyramidal Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo2-create",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to create a pyramidal neuron\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Can you create a Layer 2/3 pyramidal neuron for me with realistic biological parameters? \"\n",
    "    \"Please explain why you chose those specific parameter values.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo3-header",
   "metadata": {},
   "source": [
    "## Demo 3: Executing the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo3-execute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM what to do next and execute the neuron\n",
    "response = run_snnbuilder_demo(\n",
    "    \"What should I do next with the pyramidal neuron I created? \"\n",
    "    \"Please execute it and show me what happens. Explain each step.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo4-header",
   "metadata": {},
   "source": [
    "## Demo 4: Generating Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to generate standalone Python code\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Can you generate standalone Python code for the pyramidal neuron that I can run independently? \"\n",
    "    \"Please explain what the code does and how to use it.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo5-header",
   "metadata": {},
   "source": [
    "## Demo 5: Creating an Inhibitory Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo5-inhibitory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to create an inhibitory neuron\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Now create a fast-spiking inhibitory interneuron with appropriate parameters. \"\n",
    "    \"Make it different from the pyramidal neuron with faster dynamics. \"\n",
    "    \"Explain the biological differences between excitatory and inhibitory neurons.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo6-header",
   "metadata": {},
   "source": [
    "## Demo 6: Managing Multiple Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo6-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to show all created neurons\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Show me all the neurons I've created so far and their status. \"\n",
    "    \"Execute any that haven't been executed yet and compare their properties.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo7-header",
   "metadata": {},
   "source": [
    "## Demo 7: Custom Neuron with Specific Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo7-advanced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to create a neuron with specific custom parameters\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Create a custom neuron with these specific parameters: \"\n",
    "    \"threshold at -45 mV, membrane capacitance of 150 pF, \"\n",
    "    \"time constant of 12 ms, and dendritic extent of 250 micrometers. \"\n",
    "    \"Make it an excitatory neuron, execute it immediately, and generate the code.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo8-header",
   "metadata": {},
   "source": [
    "## Demo 8: Educational Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo8-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to compare different neuron types\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Can you explain the differences between the pyramidal neuron and inhibitory neuron I created? \"\n",
    "    \"What are the key parameter differences and why are they important for their biological functions? \"\n",
    "    \"How do these differences affect their role in neural circuits?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo9-header",
   "metadata": {},
   "source": [
    "## Demo 9: Best Practices and Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo9-help",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM for help with common issues\n",
    "response = run_snnbuilder_demo(\n",
    "    \"What are some common mistakes when creating neurons? \"\n",
    "    \"Can you give me best practices for choosing neuron parameters? \"\n",
    "    \"What should I consider when modeling different types of neurons?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo10-header",
   "metadata": {},
   "source": [
    "## Demo 10: Complete Workflow Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo10-workflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to demonstrate a complete workflow\n",
    "response = run_snnbuilder_demo(\n",
    "    \"Show me a complete workflow: create a cortical neuron, execute it, \"\n",
    "    \"generate the Python code, and explain what each step does. \"\n",
    "    \"Make it educational for someone learning computational neuroscience. \"\n",
    "    \"Include tips for extending this to build neural networks.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive-section",
   "metadata": {},
   "source": [
    "# üéÆ Interactive Mode\n",
    "\n",
    "Now you can ask your own questions! Use the cell below to interact directly with the SNNbuilder MCP system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own questions here!\n",
    "your_question = \"Create a hippocampal CA1 pyramidal neuron with realistic parameters and explain its properties\"\n",
    "\n",
    "response = run_snnbuilder_demo(your_question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# üéØ Conclusion: The Future of AI-Augmented Neuroscience\n",
    "\n",
    "Congratulations! You've just experienced the future of computational neuroscience. Here's what makes this approach revolutionary:\n",
    "\n",
    "## üß† **Key Benefits Demonstrated**\n",
    "\n",
    "### **1. Natural Language Interface**\n",
    "- **Before**: Complex APIs, parameter documentation, trial-and-error\n",
    "- **Now**: \"Create a pyramidal neuron with realistic parameters\"\n",
    "\n",
    "### **2. Educational Value**\n",
    "- **AI Tutor**: LLM explains neuroscience concepts in context\n",
    "- **Parameter Guidance**: Realistic values with biological justification\n",
    "- **Best Practices**: Built-in domain expertise\n",
    "\n",
    "### **3. Rapid Prototyping**\n",
    "- **Idea to Code**: Minutes instead of hours\n",
    "- **Automatic Documentation**: Generated code is self-documenting\n",
    "- **Reproducible Science**: Standalone, shareable code\n",
    "\n",
    "### **4. Domain Knowledge Integration**\n",
    "- **Biological Constraints**: Realistic parameter ranges\n",
    "- **Neuroscience Expertise**: Built into the AI agent\n",
    "- **Error Prevention**: Validation and guidance\n",
    "\n",
    "## üöÄ **Technical Innovation**\n",
    "\n",
    "### **Rich Schema System**\n",
    "Your SNNbuilder `NODE_DEFINITION` provides perfect documentation for LLM understanding:\n",
    "- **Type-Safe Parameters**: Prevents errors through validation\n",
    "- **Comprehensive Descriptions**: Every parameter explained\n",
    "- **Biological Context**: Real-world relevance\n",
    "\n",
    "### **MCP Protocol Integration**\n",
    "- **Standardized Communication**: LLM ‚Üî Neuroscience tools\n",
    "- **Tool Discovery**: AI agents understand available capabilities\n",
    "- **Extensible Architecture**: Easy to add new nodes and features\n",
    "\n",
    "## üåç **Impact on the Field**\n",
    "\n",
    "### **Democratization**\n",
    "- **Accessibility**: Non-experts can build sophisticated models\n",
    "- **Education**: Learn through natural conversation\n",
    "- **Collaboration**: Easy sharing through natural language descriptions\n",
    "\n",
    "### **Research Acceleration**\n",
    "- **Rapid Iteration**: Test ideas quickly\n",
    "- **Standardization**: Consistent use of best practices\n",
    "- **Knowledge Transfer**: AI explanations help understanding\n",
    "\n",
    "### **Reproducible Science**\n",
    "- **Documented Workflows**: Every step explained\n",
    "- **Standalone Code**: No dependency on specific environments\n",
    "- **Version Control**: Generated code can be tracked\n",
    "\n",
    "## üîÆ **What's Next?**\n",
    "\n",
    "This demo shows just the beginning. Imagine:\n",
    "\n",
    "- **Complete Neural Networks**: \"Build a cortical microcircuit with realistic connectivity\"\n",
    "- **Multi-Scale Models**: From molecules to behavior\n",
    "- **Experimental Design**: AI-guided parameter exploration\n",
    "- **Real-Time Analysis**: Interactive model refinement\n",
    "- **Cross-Platform Integration**: SONATA, Allen Institute, Blue Brain Project\n",
    "\n",
    "## üí° **Try It Yourself**\n",
    "\n",
    "- **Experiment**: Ask different questions in the interactive cell above\n",
    "- **Extend**: Add more SNNbuilder nodes to the MCP server\n",
    "- **Integrate**: Connect with your existing neuroscience workflows\n",
    "- **Share**: Show colleagues the power of AI-augmented research\n",
    "\n",
    "---\n",
    "\n",
    "**You've just witnessed the future of computational neuroscience: AI-augmented research where human expertise is amplified by intelligent agents capable of understanding and manipulating complex neuroscience workflows through natural conversation!** üß†ü§ñ‚ú®\n",
    "\n",
    "**Ready to revolutionize your research? The tools are in your hands!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
